defaults:
  - task: clip_pretrain  # Our new training task
  - model: multimodal/clip   # Our new CLIP model
  - data: flickr8k         # Our new Flickr8k datamodule
  - trainer: default       # Default Pytorch Lightning trainer
  - callbacks: default   # Default callbacks (checkpointing, etc.)
  - _self_

# --- Project Settings ---
project_name: "vision_vlm_vla"
# Experiment name is dynamic based on task and model
experiment_name: ${task.name}_${model.name}_${data.name}
# All outputs will be saved here
output_dir: ./outputs/${experiment_name}
seed: 42

# --- Mode ---
# 'train' to run training
# 'eval' to run evaluation
mode: train


# Logging
logging:
  wandb:
    enable: false
    project: ${project_name}
    name: ${experiment_name}
  tensorboard:
    enable: true
  log_every_n_steps: 10

eval_checkpoint_path: null # e.g., "outputs/clip_pretrain_clip/checkpoints/best.ckpt"

# Resume training
resume_from: null